
# Operationizing Machine Learning Pipelines by Thomas Choong

This project is part of the Machine Learning Engineer with Azure Nanodegree program. This is project #2 and I am tasked to use Azure & Python SDK & Swagger to create a model (using AutoML), select best model, deploy best model via an endpoint, publish the endpoint and finally consume it via HTTP API.

## Architectural Diagram
1.) Authentication - Using Git Bash to login into Azure via 'az login' command
<br>2.) Auto ML Experiment - Upload the banking data and run AutoML to retrieve the best performing model
<br>3.) Deploying the Best Model - Using the results from AutoML, I've selected the best performing model (Accuracy) and deployed it 
<br>4.) Enable Logging - Before we consume the model we must activate logging insights via Git Bash, this allows us to see real-time stats of any errors or issues before & during consumption of the model
<br>5.) Swagger Documentation - Swagger is used to consume the model and enabling the API to have access to the end model. 
<br>6.) Consume Model Endpoints - 
<br>7.) Publish Pipeline - 

## Key Steps


<img src="https://github.com/thomascjw30/operationalizing-ml-pipeline/blob/main/Screenshots/automl-run.PNG">

## Screen Recording
*TODO* Provide a link to a screen recording of the project in action. Remember that the screencast should demonstrate:

## Standout Suggestions
*TODO (Optional):* This is where you can provide information about any standout suggestions that you have attempted.
